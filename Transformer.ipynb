{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 0\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import itertools\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:57.236722Z",
     "iopub.status.busy": "2021-04-02T02:32:57.236089Z",
     "iopub.status.idle": "2021-04-02T02:32:57.237824Z",
     "shell.execute_reply": "2021-04-02T02:32:57.238198Z"
    },
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:57.243772Z",
     "iopub.status.busy": "2021-04-02T02:32:57.243178Z",
     "iopub.status.idle": "2021-04-02T02:32:57.245398Z",
     "shell.execute_reply": "2021-04-02T02:32:57.244918Z"
    },
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],np.arange(d_model)[np.newaxis, :],d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:57.969177Z",
     "iopub.status.busy": "2021-04-02T02:32:57.968477Z",
     "iopub.status.idle": "2021-04-02T02:32:57.970608Z",
     "shell.execute_reply": "2021-04-02T02:32:57.970998Z"
    },
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:57.985923Z",
     "iopub.status.busy": "2021-04-02T02:32:57.985280Z",
     "iopub.status.idle": "2021-04-02T02:32:57.987968Z",
     "shell.execute_reply": "2021-04-02T02:32:57.987475Z"
    },
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:58.004250Z",
     "iopub.status.busy": "2021-04-02T02:32:58.003576Z",
     "iopub.status.idle": "2021-04-02T02:32:58.006299Z",
     "shell.execute_reply": "2021-04-02T02:32:58.005763Z"
    },
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:58.435764Z",
     "iopub.status.busy": "2021-04-02T02:32:58.435152Z",
     "iopub.status.idle": "2021-04-02T02:32:58.436974Z",
     "shell.execute_reply": "2021-04-02T02:32:58.437356Z"
    },
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:58.479456Z",
     "iopub.status.busy": "2021-04-02T02:32:58.478868Z",
     "iopub.status.idle": "2021-04-02T02:32:58.480995Z",
     "shell.execute_reply": "2021-04-02T02:32:58.480432Z"
    },
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:58.519367Z",
     "iopub.status.busy": "2021-04-02T02:32:58.518766Z",
     "iopub.status.idle": "2021-04-02T02:32:58.521037Z",
     "shell.execute_reply": "2021-04-02T02:32:58.520517Z"
    },
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:58.589255Z",
     "iopub.status.busy": "2021-04-02T02:32:58.584701Z",
     "iopub.status.idle": "2021-04-02T02:32:58.591431Z",
     "shell.execute_reply": "2021-04-02T02:32:58.590964Z"
    },
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training,look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)#(batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:58.662723Z",
     "iopub.status.busy": "2021-04-02T02:32:58.662097Z",
     "iopub.status.idle": "2021-04-02T02:32:58.663689Z",
     "shell.execute_reply": "2021-04-02T02:32:58.664087Z"
    },
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding,self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:58.970031Z",
     "iopub.status.busy": "2021-04-02T02:32:58.964834Z",
     "iopub.status.idle": "2021-04-02T02:32:58.971799Z",
     "shell.execute_reply": "2021-04-02T02:32:58.972188Z"
    },
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.196786Z",
     "iopub.status.busy": "2021-04-02T02:32:59.196146Z",
     "iopub.status.idle": "2021-04-02T02:32:59.198307Z",
     "shell.execute_reply": "2021-04-02T02:32:59.197729Z"
    },
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.tokenizer = Encoder(num_layers, d_model, num_heads, dff,input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask,look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.tokenizer(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.711204Z",
     "iopub.status.busy": "2021-04-02T02:32:59.710614Z",
     "iopub.status.idle": "2021-04-02T02:32:59.712227Z",
     "shell.execute_reply": "2021-04-02T02:32:59.712625Z"
    },
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_warmup_steps = 4000#4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.719045Z",
     "iopub.status.busy": "2021-04-02T02:32:59.718425Z",
     "iopub.status.idle": "2021-04-02T02:32:59.720119Z",
     "shell.execute_reply": "2021-04-02T02:32:59.720526Z"
    },
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=t_warmup_steps):#4000\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.724285Z",
     "iopub.status.busy": "2021-04-02T02:32:59.723670Z",
     "iopub.status.idle": "2021-04-02T02:32:59.726235Z",
     "shell.execute_reply": "2021-04-02T02:32:59.726614Z"
    },
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.730814Z",
     "iopub.status.busy": "2021-04-02T02:32:59.730209Z",
     "iopub.status.idle": "2021-04-02T02:32:59.872618Z",
     "shell.execute_reply": "2021-04-02T02:32:59.871992Z"
    },
    "id": "f33ZCgvHpPdG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)).numpy()[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# print(math.sqrt(d_model)*math.sqrt(4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.877232Z",
     "iopub.status.busy": "2021-04-02T02:32:59.876452Z",
     "iopub.status.idle": "2021-04-02T02:32:59.878693Z",
     "shell.execute_reply": "2021-04-02T02:32:59.878280Z"
    },
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.885098Z",
     "iopub.status.busy": "2021-04-02T02:32:59.884379Z",
     "iopub.status.idle": "2021-04-02T02:32:59.886315Z",
     "shell.execute_reply": "2021-04-02T02:32:59.886703Z"
    },
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.897336Z",
     "iopub.status.busy": "2021-04-02T02:32:59.896730Z",
     "iopub.status.idle": "2021-04-02T02:32:59.904570Z",
     "shell.execute_reply": "2021-04-02T02:32:59.905002Z"
    },
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 13\n",
      "24 24\n"
     ]
    }
   ],
   "source": [
    "dp_conf = [('ain',10),('aot',10),('m',10),('din',10),('dot',10)]\n",
    "# dp_conf = [('m',10)]\n",
    "# dp_val_range = 255\n",
    "dp_val_range = 256\n",
    "\n",
    "def getDpList():\n",
    "    l = []\n",
    "    for pair in dp_conf:\n",
    "        dp = pair[0]\n",
    "        num = pair[1]\n",
    "        for i in range(num):\n",
    "            l.append(dp+str(i))\n",
    "\n",
    "    return l\n",
    "\n",
    "def assignOperation(allDpList):\n",
    "    l = []\n",
    "    for dp in allDpList:\n",
    "        for num in range(dp_val_range):\n",
    "#             if num<100:\n",
    "#                 continue\n",
    "            num_str = str(num)\n",
    "            \n",
    "            x = \"assign \"+num_str +\" to \"+ dp\n",
    "            \n",
    "            if dp[0] == 'a':\n",
    "                num_str+='.0'\n",
    "                \n",
    "            y = dp +\"=\"+ num_str +\";\"\n",
    "#             print(y)\n",
    "            l.append([x,y])\n",
    "#             print([x,y])\n",
    "  \n",
    "    return l\n",
    "\n",
    "def test():\n",
    "    l = []\n",
    "    for num in range(10000):\n",
    "        x = list(str(num))\n",
    "        y = list(x)\n",
    "        y.reverse()\n",
    "        l.append([x,y])\n",
    "    return l\n",
    "\n",
    "def createDict(_li):\n",
    "    _max_len = len(max(_li, key=len))\n",
    "\n",
    "    _set = sorted(set(itertools.chain.from_iterable(_li)))\n",
    "\n",
    "    _set.remove('<START>')\n",
    "    _set.remove('<END>')\n",
    "    _li = list(_set)\n",
    "    _li = ['<PAD>','<UNK>','<START>','<END>'] + _li\n",
    "    \n",
    "    _dict = {_li[i]: i for i in range(len(_li))}\n",
    "    _dict_inv = {i: _li[i] for i in range(len(_li))}\n",
    "\n",
    "    return _max_len, _dict, _dict_inv\n",
    "    \n",
    "def createDataSet():\n",
    "    dp_list = getDpList()\n",
    "    \n",
    "    dataset = []\n",
    "\n",
    "    dataset += assignOperation(dp_list)\n",
    "#     dataset += test()\n",
    "    \n",
    "    for row in dataset:\n",
    "        x_li = ['<START>']\n",
    "        x_li = x_li + list(row[0])\n",
    "        x_li.append('<END>')\n",
    "        row[0] = x_li\n",
    "        \n",
    "        y_li = ['<START>']\n",
    "        y_li = y_li + list(row[1])\n",
    "        y_li.append('<END>')\n",
    "        row[1] = y_li\n",
    "\n",
    "#     test_dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(20000)\n",
    "#     dataset += test_dataset\n",
    "\n",
    "    X, Y = zip(*dataset)\n",
    "    \n",
    "    createDict(X)\n",
    "    \n",
    "    Tx, X_dict, X_dict_inv = createDict(X)\n",
    "    Ty, Y_dict, Y_dict_inv = createDict(Y)\n",
    "    \n",
    "    setting = {}\n",
    "    setting['Tx'] = Tx\n",
    "    setting['Ty'] = Ty\n",
    "    setting['X_dict'] = X_dict\n",
    "    setting['Y_dict'] = Y_dict\n",
    "    setting['X_dict_inv'] = X_dict_inv\n",
    "    setting['Y_dict_inv'] = Y_dict_inv\n",
    "    x_vocab_len = len(X_dict)\n",
    "    y_vocab_len = len(Y_dict)\n",
    "    setting['x_vocab_len'] = x_vocab_len\n",
    "    setting['y_vocab_len'] = y_vocab_len\n",
    "    \n",
    "    np.save(\"npy/setting.npy\", setting)\n",
    "    \n",
    "#     print(setting)\n",
    "    \n",
    "    encoded_x = [[X_dict[j] for j in i] for i in X]\n",
    "    encoded_y = [[Y_dict[j] for j in i] for i in Y]\n",
    "    \n",
    "    padded_x = pad_sequences(encoded_x, padding=\"post\")\n",
    "    padded_y = pad_sequences(encoded_y, padding=\"post\")\n",
    "\n",
    "\n",
    "    shuffled_xLabel, shuffled_yLabel = shuffle(padded_x, padded_y, random_state=seed_value) #0\n",
    "#     shuffled_xLabel = padded_x\n",
    "#     shuffled_yLabel = padded_y\n",
    "\n",
    "    train_XLabel, test_XLabel = np.split(shuffled_xLabel, [int(len(shuffled_xLabel)*0.9)])\n",
    "    train_YLabel, test_YLabel = np.split(shuffled_yLabel, [int(len(shuffled_yLabel)*0.9)])\n",
    "    \n",
    "    np.save('npy/train_XLabel.npy', train_XLabel)\n",
    "    np.save('npy/test_XLabel.npy', test_XLabel)\n",
    "    np.save('npy/train_YLabel.npy', train_YLabel)\n",
    "    np.save('npy/test_YLabel.npy', test_YLabel)\n",
    "    \n",
    "def loadDataSet():\n",
    "    setting = np.load('npy/setting.npy',allow_pickle='TRUE').item()\n",
    "    \n",
    "    train_XLabel = np.load('npy/train_XLabel.npy')\n",
    "    test_XLabel = np.load('npy/test_XLabel.npy')\n",
    "    train_YLabel = np.load('npy/train_YLabel.npy')\n",
    "    test_YLabel = np.load('npy/test_YLabel.npy')\n",
    "    \n",
    "    return setting, train_XLabel, test_XLabel, train_YLabel, test_YLabel\n",
    "\n",
    "# createDataSet()\n",
    "setting, train_XLabel, test_XLabel, train_YLabel, test_YLabel = loadDataSet()\n",
    "\n",
    "Tx = setting['Tx']\n",
    "Ty = setting['Ty']\n",
    "X_dict = setting['X_dict']\n",
    "Y_dict = setting['Y_dict']\n",
    "X_dict_inv = setting['X_dict_inv']\n",
    "Y_dict_inv = setting['Y_dict_inv']\n",
    "x_vocab_len = setting['x_vocab_len']\n",
    "y_vocab_len = setting['y_vocab_len']\n",
    "\n",
    "print(Tx, Ty)\n",
    "# print(X_dict)\n",
    "# print(Y_dict)\n",
    "# print(X_dict_inv)\n",
    "# print(Y_dict_inv)\n",
    "print(x_vocab_len, y_vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:32:59.911308Z",
     "iopub.status.busy": "2021-04-02T02:32:59.910613Z",
     "iopub.status.idle": "2021-04-02T02:33:00.021368Z",
     "shell.execute_reply": "2021-04-02T02:33:00.020843Z"
    },
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=x_vocab_len,#tokenizers.pt.get_vocab_size(),\n",
    "    target_vocab_size=y_vocab_len,#tokenizers.en.get_vocab_size(),\n",
    "    pe_input=Tx,#1000\n",
    "    pe_target=Ty,#1000\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:33:00.027040Z",
     "iopub.status.busy": "2021-04-02T02:33:00.026287Z",
     "iopub.status.idle": "2021-04-02T02:33:00.028528Z",
     "shell.execute_reply": "2021-04-02T02:33:00.028080Z"
    },
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by\n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:33:00.033637Z",
     "iopub.status.busy": "2021-04-02T02:33:00.032935Z",
     "iopub.status.idle": "2021-04-02T02:33:00.035512Z",
     "shell.execute_reply": "2021-04-02T02:33:00.035003Z"
    },
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "# checkpoint_path = \"./checkpoints/att_map\"\n",
    "\n",
    "# ckpt = tf.train.Checkpoint(transformer=transformer,optimizer=optimizer)\n",
    "\n",
    "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# # if a checkpoint exists, restore the latest checkpoint.\n",
    "# if ckpt_manager.latest_checkpoint:\n",
    "#   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "#   print('Latest checkpoint restored!!')\n",
    "# # ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=Ty):\n",
    "    encoder_input = tf.constant([[X_dict['<START>']]+[X_dict[j] for j in sentence]],dtype=\"int64\")\n",
    "    output = tf.constant([[2]],dtype=\"int64\")\n",
    "    end = tf.constant([[3]],dtype=\"int64\")\n",
    "\n",
    "    for i in range(max_length):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(encoder_input,output,False,\n",
    "                                             enc_padding_mask,\n",
    "                                             combined_mask,\n",
    "                                             dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == end:\n",
    "            break\n",
    "    \n",
    "    text = [Y_dict_inv[j] for j in output.numpy()[0]]\n",
    "    tokens = text\n",
    "    tokens = tf.constant([tokens])\n",
    "\n",
    "    text = list(filter(lambda x: x != '<END>' , text))\n",
    "    text = list(filter(lambda x: x != '<START>' , text))\n",
    "\n",
    "    text = ''.join(text)\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map(file_name = None):\n",
    "    sentence = \"assign 253 to aot8\"\n",
    "    input_text = list(sentence)\n",
    "    translated_text, translated_tokens, attention_weights = evaluate(sentence)\n",
    "\n",
    "    output_text = list(translated_text)\n",
    "\n",
    "    head = 0\n",
    "    # shape: (batch=1, num_heads, seq_len_q, seq_len_k)\n",
    "    attention_heads = tf.squeeze(attention_weights['decoder_layer4_block2'], 0)\n",
    "    \n",
    "    li = []\n",
    "\n",
    "    for h, head in enumerate(attention_heads):\n",
    "        head = np.delete(head, -1, 0)\n",
    "        head = np.delete(head, 0, 1)\n",
    "        li.append(head)\n",
    "    \n",
    "#     li_c = li[0] + li[1] + li[2] + li[3] + li[4] + li[5] + li[6] + li[7]\n",
    "#     li_c = li_c/8\n",
    "\n",
    "    comp = li[2]\n",
    "    comp[8] = li[0][8]\n",
    "    comp[9] = li[0][9]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "#     attention = attention_heads[head]\n",
    "    \n",
    "\n",
    "    \n",
    "#     attention = np.delete(attention, -1, 0)\n",
    "#     attention = np.delete(attention, 0, 1)\n",
    "    \n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    axData = ax.imshow(comp, cmap=\"viridis\")\n",
    "#     axData = ax.imshow(li_c, cmap=\"Greens\")\n",
    "    colorBar = fig.colorbar(axData, orientation='horizontal',shrink=0.9)\n",
    "    colorBar.ax.set_xlabel('$Attention\\;weights$', labelpad=2)\n",
    "    \n",
    "    title = \"$epoch:\"+\"90\"+\"\\;batch:\"+\"0\"+\"$\"\n",
    "\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    ax.set_xticks(range(len(input_text)))\n",
    "    ax.set_xticklabels(input_text, rotation=0)\n",
    "\n",
    "    ax.set_yticks(range(len(output_text)))\n",
    "    ax.set_yticklabels(output_text)\n",
    "\n",
    "    ax.set_xlabel('$Input\\;Sequence$')\n",
    "    ax.set_ylabel('$Output\\;Sequence$')\n",
    "    \n",
    "    ax.grid()\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name, dpi=300)\n",
    "        plt.close(fig)\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "# plot_attention_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_one_attention_head(input_text,output_text,attention):\n",
    "    attention = np.delete(attention, -1, 0)\n",
    "    attention = np.delete(attention, 0, 1)\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.imshow(attention)\n",
    "\n",
    "    ax.set_xticks(range(len(input_text)))\n",
    "    ax.set_yticks(range(len(output_text)))\n",
    "\n",
    "\n",
    "    ax.set_xticklabels(input_text)\n",
    "    ax.set_yticklabels(output_text)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_all_attention_head(file_name = None):\n",
    "    sentence = \"assign 253 to aot8\"\n",
    "    input_text = list(sentence)\n",
    "    translated_text, translated_tokens, attention_weights = evaluate(sentence)\n",
    "    output_text = list(translated_text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    attention_heads = tf.squeeze(attention_weights['decoder_layer4_block2'], 0)\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    for h, head in enumerate(attention_heads):\n",
    "        ax = fig.add_subplot(2, 4, h+1)\n",
    "\n",
    "        plot_one_attention_head(input_text, output_text, head)\n",
    "\n",
    "        ax.set_title(f'Head {h+1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "    if file_name:\n",
    "        plt.savefig(file_name, dpi=300)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "# plot_all_attention_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveAttData(epoch,batch):\n",
    "    sentence = \"assign 253 to aot8\"\n",
    "    input_text = list(sentence)\n",
    "    translated_text, translated_tokens, attention_weights = evaluate(sentence)\n",
    "    output_text = list(translated_text)\n",
    "    name = str(epoch).zfill(5)+\"_\"+str(batch).zfill(5)\n",
    "    np.save(\"att_data/npy_att/\"+name+\".npy\", attention_weights)\n",
    "    np.save(\"att_data/npy_outtext/\"+name+\".npy\", output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32#16#32#10#16\n",
    "train_XLabel_chunks = [train_XLabel[x:x+batch_size] for x in range(0, len(train_XLabel), batch_size)]\n",
    "train_YLabel_chunks = [train_YLabel[x:x+batch_size] for x in range(0, len(train_YLabel), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:33:00.039471Z",
     "iopub.status.busy": "2021-04-02T02:33:00.038817Z",
     "iopub.status.idle": "2021-04-02T02:33:00.040840Z",
     "shell.execute_reply": "2021-04-02T02:33:00.041343Z"
    },
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:33:00.048339Z",
     "iopub.status.busy": "2021-04-02T02:33:00.047600Z",
     "iopub.status.idle": "2021-04-02T02:33:00.049531Z",
     "shell.execute_reply": "2021-04-02T02:33:00.049885Z"
    },
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,True,enc_padding_mask,combined_mask,dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-02T02:33:00.055295Z",
     "iopub.status.busy": "2021-04-02T02:33:00.054675Z",
     "iopub.status.idle": "2021-04-02T02:50:06.931066Z",
     "shell.execute_reply": "2021-04-02T02:50:06.930397Z"
    },
    "id": "bbvmaKNiznHZ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 1.3051334619522095 Accuracy 0.6306353807449341\n",
      "Time taken for 1 epoch: 26.28 secs\n",
      "\n",
      "Epoch 1 Loss 0.1198729276657104 Accuracy 0.9641000628471375\n",
      "Time taken for 1 epoch: 13.30 secs\n",
      "\n",
      "Epoch 2 Loss 0.0210913922637701 Accuracy 0.9950691461563110\n",
      "Time taken for 1 epoch: 13.74 secs\n",
      "\n",
      "Epoch 3 Loss 0.0055547920055687 Accuracy 0.9987143874168396\n",
      "Time taken for 1 epoch: 14.18 secs\n",
      "\n",
      "Epoch 4 Loss 0.0000110497840069 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.24 secs\n",
      "\n",
      "Epoch 5 Loss 0.0000005607513458 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.15 secs\n",
      "\n",
      "Epoch 6 Loss 0.0848685652017593 Accuracy 0.9823902845382690\n",
      "Time taken for 1 epoch: 14.24 secs\n",
      "\n",
      "Epoch 7 Loss 0.0246072262525558 Accuracy 0.9939517378807068\n",
      "Time taken for 1 epoch: 14.42 secs\n",
      "\n",
      "Epoch 8 Loss 0.0215125959366560 Accuracy 0.9952679872512817\n",
      "Time taken for 1 epoch: 14.25 secs\n",
      "\n",
      "Epoch 9 Loss 0.0423348098993301 Accuracy 0.9915018677711487\n",
      "Time taken for 1 epoch: 14.09 secs\n",
      "\n",
      "Epoch 10 Loss 0.0509577654302120 Accuracy 0.9882485270500183\n",
      "Time taken for 1 epoch: 14.24 secs\n",
      "\n",
      "Epoch 11 Loss 0.0000157008562383 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.08 secs\n",
      "\n",
      "Epoch 12 Loss 0.0000006608692047 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.31 secs\n",
      "\n",
      "Epoch 13 Loss 0.0000000308482200 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.34 secs\n",
      "\n",
      "Epoch 14 Loss 0.0000000294089908 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.24 secs\n",
      "\n",
      "Epoch 15 Loss 0.0000000313291046 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.16 secs\n",
      "\n",
      "Epoch 16 Loss 0.0000000303389029 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.08 secs\n",
      "\n",
      "Epoch 17 Loss 0.0000000289540587 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.22 secs\n",
      "\n",
      "Epoch 18 Loss 0.0000000248839473 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.08 secs\n",
      "\n",
      "Epoch 19 Loss 0.0275458991527557 Accuracy 0.9954580664634705\n",
      "Time taken for 1 epoch: 14.17 secs\n",
      "\n",
      "Epoch 20 Loss 0.0466866493225098 Accuracy 0.9914544820785522\n",
      "Time taken for 1 epoch: 14.07 secs\n",
      "\n",
      "Epoch 21 Loss 0.0048869810998440 Accuracy 0.9988296627998352\n",
      "Time taken for 1 epoch: 14.11 secs\n",
      "\n",
      "Epoch 22 Loss 0.0000003482944635 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.20 secs\n",
      "\n",
      "Epoch 23 Loss 0.0000000143754830 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.14 secs\n",
      "\n",
      "Epoch 24 Loss 0.0000000244915714 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.13 secs\n",
      "\n",
      "Epoch 25 Loss 0.0000000264102908 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.20 secs\n",
      "\n",
      "Epoch 26 Loss 0.0000000268703513 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.20 secs\n",
      "\n",
      "Epoch 27 Loss 0.0000000203641424 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.25 secs\n",
      "\n",
      "Epoch 28 Loss 0.0000000232496280 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 14.30 secs\n",
      "\n",
      "Epoch 29 Loss 0.0000000252040664 Accuracy 1.0000000000000000\n",
      "Time taken for 1 epoch: 13.95 secs\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for i in range(2):\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "#     batc = 0\n",
    "    for train_x, train_y in zip(train_XLabel_chunks, train_YLabel_chunks):\n",
    "        train_step(tf.constant(train_x,dtype=\"int64\"), tf.constant(train_y,dtype=\"int64\"))\n",
    "#         saveAttData(epoch+ten*EPOCHS,batc)\n",
    "#         batc +=1\n",
    "#     plot_attention_map('attentionMap/'+str(epoch+ten*EPOCHS).zfill(4)+'_'+str(0).zfill(4)+'.png')\n",
    "#     plot_all_attention_head('attentionMap/'+str(epoch+ten*EPOCHS).zfill(4)+'_'+str(0).zfill(4)+'.png')\n",
    "\n",
    "    print(f'Epoch {epoch} Loss {train_loss.result():.16f} Accuracy {train_accuracy.result():.16f}')\n",
    "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "\n",
    "print(ten)\n",
    "ten += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all_attention_head('attentionMap/'+'_d_'+str(dropout_rate)+'_w_'+str(t_warmup_steps)+'_b_'+str(batch_size)+'_e_'+str(85)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all_attention_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_all_attention_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map_from_file(epoch,batch):\n",
    "    sentence = \"assign 253 to aot8\"\n",
    "    input_text = list(sentence)\n",
    "    \n",
    "    name = str(epoch).zfill(5)+\"_\"+str(batch).zfill(5)\n",
    "#         setting = np.load('npy/setting.npy',allow_pickle='TRUE').item()\n",
    "        \n",
    "    attention_weights = np.load(\"att_data/npy_att/\"+name+\".npy\",allow_pickle='TRUE').item()\n",
    "    output_text = np.load(\"att_data/npy_outtext/\"+name+\".npy\")\n",
    "#     print(output_text)\n",
    "    \n",
    "    if ''.join(output_text) != \"aot8=253.0;\":\n",
    "        return\n",
    "    \n",
    "#     if batch%10 != 0:\n",
    "#         return\n",
    "    \n",
    "#     input_text = list(sentence)\n",
    "#     translated_text, translated_tokens, attention_weights = evaluate(sentence)\n",
    "#     output_text = list(translated_text)\n",
    "\n",
    "    head = 0\n",
    "    # shape: (batch=1, num_heads, seq_len_q, seq_len_k)\n",
    "    attention_heads = tf.squeeze(\n",
    "      attention_weights['decoder_layer4_block2'], 0)\n",
    "    attention = attention_heads[head]\n",
    "    \n",
    "    attention = np.delete(attention, -1, 0)\n",
    "    attention = np.delete(attention, 0, 1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    axData = ax.imshow(attention, cmap=\"viridis\")\n",
    "    colorBar = fig.colorbar(axData, orientation='horizontal',shrink=0.9)\n",
    "    colorBar.ax.set_xlabel('$Attention\\;weights$', labelpad=2)\n",
    "    \n",
    "    title = \"$epoch:\"+\"90\"+\"\\;batch:\"+\"0\"+\"$\"\n",
    "\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    ax.set_xticks(range(len(input_text)))\n",
    "    ax.set_xticklabels(input_text, rotation=0)\n",
    "\n",
    "    ax.set_yticks(range(len(output_text)))\n",
    "    ax.set_yticklabels(output_text)\n",
    "\n",
    "    ax.set_xlabel('$Input\\;Sequence$')\n",
    "    ax.set_ylabel('$Output\\;Sequence$')\n",
    "    \n",
    "    ax.grid()\n",
    "    \n",
    "#     if file_name:\n",
    "    plt.savefig('attentionMap/'+name+'.png', dpi=300)\n",
    "    plt.close(fig)\n",
    "# plot_attention_map_from_file(88,115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(30):\n",
    "#     if i<16 or i>17:\n",
    "#         continue\n",
    "#     for j in range(720):\n",
    "#         if j%10 ==0:\n",
    "#             plot_attention_map_from_file(i,j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_attention_map_from_file(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformer.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
